<!DOCTYPE html>
<html>
<head>
    <title>Week 4: Hadoop Ecosystem Tools - Part 1</title>
</head>
<body>
    <h2>Hadoop Pig: Data Processing with Pig Latin</h2>
    <p>Hadoop Pig is a high-level platform for processing and analyzing large datasets in Hadoop. It simplifies the task of writing complex MapReduce jobs by providing a higher-level language called Pig Latin. Pig Latin scripts are translated into a series of MapReduce jobs, allowing users to express data transformations more easily.</p>
    <h3>Example: Processing Data with Pig Latin</h3>
    <pre>
        <code>
            -- Load data from a text file
            data = LOAD 'input.txt' USING PigStorage(',') AS (id:int, name:chararray, age:int);
            -- Filter the data to include only records with age greater than 25
            filtered_data = FILTER data BY age > 25;
            -- Store the filtered data into an output file
            STORE filtered_data INTO 'output' USING PigStorage(',');
        </code>
    </pre>
    <p>In this example:</p>
    <ul>
        <li>We load data from a text file using the <code>LOAD</code> statement, specifying the schema of the data.</li>
        <li>We filter the data using the <code>FILTER</code> statement, keeping only records where the 'age' column is greater than 25.</li>
        <li>Finally, we store the filtered data into an output file using the <code>STORE</code> statement.</li>
    </ul>
    <h2>Hadoop Hive: Data Warehousing and Querying</h2>
    <p>Hadoop Hive is a data warehousing and SQL-like query language tool for Hadoop. It allows users to query large datasets stored in HDFS using a language called HiveQL. Hive translates HiveQL queries into a series of MapReduce jobs, making it accessible to those familiar with SQL.</p>
    <h3>Example: Querying Data with HiveQL</h3>
    <pre>
        <code>
            -- Create a table
            CREATE TABLE employee (
              id INT,
              name STRING,
              age INT
            );
            -- Load data into the table from an external file
            LOAD DATA INPATH '/path/to/input/data' INTO TABLE employee;
            -- Query the table to get the average age of employees
            SELECT AVG(age) FROM employee;
        </code>
    </pre>
    <p>In this example:</p>
    <ul>
        <li>We create a table named 'employee' with columns 'id,' 'name,' and 'age.'</li>
        <li>We load data from an external file into the 'employee' table using the <code>LOAD DATA</code> statement.</li>
        <li>We execute a SQL-like <code>SELECT</code> query to calculate the average age of employees.</li>
    </ul>
    <h2>Practical Exercises with Pig and Hive</h2>
    <h3>Pig Exercise:</h3>
    <p>Assume you have a CSV file named 'sales_data.csv' with the following columns: 'product_id,' 'date,' 'quantity_sold,' and 'revenue.'</p>
    <p>Your task is to use Pig Latin to calculate the total revenue for each product.</p>
    <pre>
        <code>
            <!-- Insert your Pig Latin code here -->
        </code>
    </pre>
    <h3>Hive Exercise:</h3>
    <p>Assume you have a table named 'orders' with the following columns: 'order_id,' 'customer_id,' 'order_date,' and 'total_amount.'</p>
    <p>Your task is to use HiveQL to find the total revenue generated by each customer.</p>
    <pre>
        <code>
            <!-- Insert your HiveQL query here -->
        </code>
    </pre>
    <p>These exercises demonstrate how Pig and Hive simplify data processing and querying in the Hadoop ecosystem, making it more accessible to users who are familiar with SQL-like languages and scripting languages.</p>
</body>
</html>